#spark.master = local[*]
#spark.submit.deployMode = client
#spark.driver.memory = 2g
#spark.serializer = org.apache.spark.serializer.KryoSerializer
#spark.kryo.unsafe = true
#spark.sql.warehouse.dir = /tmp/spark-warehouse
#spark.hadoop.mapreduce.fileoutputcommitter.algorithm.version = 2
#spark.hadoop.mapreduce.fileoutputcommitter.marksuccessfuljobs = false

spark.master = yarn
spark.submit.deployMode = cluster
spark.sql.shuffle.partitions = 80
spark.executor.instances = 10
spark.executor.memory = 8g
spark.executor.cores = 4
spark.driver.memory = 8g
spark.driver.cores = 4
spark.yarn.maxAppAttempts = 1
spark.serializer = org.apache.spark.serializer.KryoSerializer
spark.kryo.unsafe = true
spark.hadoop.mapreduce.fileoutputcommitter.algorithm.version = 2
spark.hadoop.mapreduce.fileoutputcommitter.marksuccessfuljobs = false
